p8105_hw2_yg2907
================
Yuandi Gao
2023-10-03

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# Problem 1

Importing and cleaning the pols-month.csv dataset:

``` r
pols_df = read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.numeric(year),
    month = month.name[as.numeric(month)],
    president = ifelse(
      prez_gop > prez_dem, "gop", "dem"
    )
  ) |> 
  select(-day, -prez_gop, -prez_dem)
```

Importing and cleaning the snp.csv dataset:

``` r
snp_df = 
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  mutate(
    date = format(as.Date(date, format = "%m/%d/%y"), "%Y/%m/%d")
  ) |> 
  separate(date, into = c("year", "month", "day"), sep = "/") |> 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.numeric(year),
    year = ifelse(year > 2023, year - 100, year)
  ) |> 
  select(-day)
```

Tidy the `unemployment.csv`

``` r
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |> 
  mutate(
    year = as.numeric(year),
    month = month.name[match(month, tolower(month.abb))]
  )
```

Merging the 3 datasets

``` r
result_df = left_join(pols_df,snp_df, by = c("year", "month")) |> 
  left_join(unemployment_df, by = c("year", "month"))
```

## Problem 2

Read and clean the `Mr. Trash Wheel` sheet \* clean names and remove
unnecessary rows \* Add trash wheel identifying name \* Recalculating
homes powered

``` r
trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Mr. Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  select(-x15, -x16) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Mr. Trash Wheel",
    year = as.numeric(year)
  )
```

Perform similar cleaning as above

``` r
gwynnda_trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Gwynnda Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Gwynnda Trash Wheel",
    year = as.numeric(year)
  )

prof_trash_wheel_df = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                     sheet = "Professor Trash Wheel", skip = 1) |> 
   janitor::clean_names() |>
  drop_na(dumpster) |> 
  mutate(
    homes_powered = (weight_tons*500)/30,
    trash_wheel_name = "Professor Trash Wheel",
    year = as.numeric(year)
  )
```

Combining three datasets

``` r
trashwheel_master = bind_rows(trash_wheel_df, prof_trash_wheel_df, gwynnda_trash_wheel_df) |> select(trash_wheel_name = "trash_wheel_name", everything())
```

*The `Mr trash wheel` sheet has 584 observations and 15 columns. * The
`Professor Trash Wheel` sheet has 106 observations and 14 columns. \*
The `Gwynnda Trash Wheel` sheet has 155 observations and 13 columns.

These datasets record details of trash collected, with key variables
such as dumpster id, date, weight, and litter type such as plastic
bottles, cigarette butts, glass bottles, etc. There are missing data in
`glass_bottles`, `sports balls` and `wrappers` in some column, meaning
that these trash was not collected by those specific dumpsters.

- The total weight of trash collected by Professor trash wheel is 216.26
  tons.
- The total number of cigarette butts collected by Gwynnda in July of
  2021 is 16300.

### Problem 3

Import, clean, and tidy the dataset of baseline demographics. Ensure
that sex and APOE4 carrier status are appropriate encoded (i.e. not
numeric), and remove any participants who do not meet the stated
inclusion criteria (i.e. no MCI at baseline).

``` r
baseline = 
  read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      0 ~ "female"
    ),
    apoe4 = case_match(
      apoe4,
      1 ~ "carrier",
      0 ~ "non-carrier"
    )
  ) |> 
  filter(age_at_onset == "." | age_at_onset > current_age)
```

The important steps in importing this dataset: - Recode binary variables
and remove ineligible participants by removing all records whose onset
for MCI is earlier or at the same age at baseline. 4 participants were
removed, the demographics information at baseline is complete. - 479
participants were recruited at baseline. - 93 participants developed MCI
during the study. - The average baseline age is 65. - Proportion of
women who are APOE 4 carrier is 30%.

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

``` r
amyloid = 
  read_csv("data/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() |> 
  rename("id" = "study_id") 
```

Pivot `amyloid` from wide to long format

``` r
amyloid_long = amyloid |> pivot_longer(
  baseline:time_8,
  names_to = "visit",
  values_to = "amyloid_ratio"
)
```

Steps on the import process and the features of the dataset. - Besides
from cleaning names, the study_id has to be renamed to match the
`baseline` dataset to proceed with merge. - There are 487 participants
in the longitudinal dataset, and MCI is recorded at baseline, time 2,
time 4, time 6, and time 8. - There are a significant amount of missing
values meaning that many participants missed visits.

Merge the amyloid dataset with baseline, keeping participants in either
sets

``` r
amyloid_full = 
  full_join(baseline, amyloid, by = c("id"))
```

- There are 16 participants in the amyloid set but not in the baseline
  set.
- There are 8 participants in the baseline set but not in the amyloid
  set.

Merge the amyloid long format dataset with baseline to keep those in
both datasets

``` r
amyloid_both = 
  inner_join(baseline, amyloid_long, by = c("id"))
```

- There are 471 participants that are in both the baseline and
  longitudinal visit datasets.
- There are 2355 rows and 8 columns in the merged dataset.

Exporting the result dataframe to a csv file

``` r
write.csv(amyloid_both, "data/baseline_amyloid_merged.csv", row.names = FALSE)
```
